# AI/ML
---

## AI Intro
- An important evolution in computer science and data processing.
- Artificial intelligence generally refers to processes and algorithms that are able to simulate human intelligence and mimic cognitive functions such as perception, learning and problem solving.
- Uses mathematics and statistics to identify patterns in data without being explicitly programmed.
- Modern applications include:
    - Modern web search engines.
    - Personal assistant programs that understand human language.
    - Self-driving vehicles.
    - Recommendation engines.
- Subsets:
    - Machine learning (ML).
    - Deep learning (Dl).

---

## Types/levels/stages:
- Reactive machines:
    - Able to perform basic operations based on some form of input.
    - No "learning" happens.
        - No ability to evolve over time.
    - The system is trained on a particular task (or set of tasks) and does not deviate from that.
    - E.g.: recommendation engines, such as Google’s AlphaGo AI, IBM’s Deep Blue chess AI, etc.
- Limited memory AI:
    - Able to store input and data.
    - Improves ("learns") over time.
    - Where machine learning (ML) begins.
    - The most advanced AIs to date (as of 2023).
    - E.g.: self-driving vehicles, virtual voice assistants, chatbots, etc.
- Theory of mind:
    - A theoretical type of AI (as of 2023). Not achieved yet.
    - Begins to understand human thoughts and emotions.
    - Understands the needs of other intelligent entities.
        - (The “theory of mind” terminology comes from psychology).
    - Meaningful AI<->human interactions (I.e. reciprocal relationship).
- Sef-awareness:
    - AIs have human-level consciousness, aware of themselves, with similar desires and emotions as humans.
- (others):
    - Artificial General Intelligence (AGI):
        - Exhibit human-like intelligence, learning from diverse data and adapting to new tasks without explicit programming.
    - Superintelligent AI:
        - Surpasses human intelligence and capabilities in all aspects.
        - Rapidly tackle complex problems, process vast amounts of information instantly, and potentially outperform even the brightest human minds.
        - Makes its actions and outcomes challenging for us to grasp or anticipate.
        - Fictional (as of 2023) E.g.: HAL 9000 from “2001: A Space Odyssey.”
    - Transcendent AI:
        - An hypothetical stage of AI.
        - Goes beyond our comprehension, potentially reaching a level of consciousness that challenges our understanding, that defies our cognitive boundaries.
        - Fictional (as of 2023) E.g.: full-scale Terminator.

---

## Machine learning
- A subset of AI that falls within the “limited memory” category.
- Instead of explicitly programming rules, historical data is used to identify rules based on data. The patterns found through ML are then used to create a model to make predictions by using new and previously unseen data.
- Common machine learning problems:
    - Categorizing data: Organize news articles by topic.
    - Predicting a numerical value: Estimate the price of a home.
    - Grouping items with similar characteristics: Segment customers.
    - Recommending items: Recommend movies.
    - Classifying images: Tag an image based on its contents.
    - Detecting objects in an image: Detect pedestrians and bicycles at an intersection.
- Training:
    - A process in which an algorithm is taught to correctly interpret data and make accurate decisions based on that data, in order to solve certain tasks.
    - Input (dataset):
        - Labels: What is being predicted.
        - Features: inputs used to predict the label.
    - Overfitting:
        - Occurs when the model gives accurate predictions for the training data, but not for new data.
- Types of algorithms:
    - Supervised learning:
        - The simplest algo.
        - Actively supervised throughout the learning process.
        - Researchers or data scientists provide the input to process and learn from, as well as some example output of what that data should be produced.
        - Results in an agent that can predict output based on new input data.
        - Continues to learn by storing and re-analysing output to improve accuracy.
        - E.g.: image-recognition, media recommendation systems, predictive analytics (regression), spam detection.
    - Unsupervised learning:
        - Involves no help from humans during the learning process.
        - The agent is given the input to analyse, and independently identifies patterns (labels) in that data.
        - Can recognize more and different patterns in any given set of data than humans.
        - Can also learn and improve over time.
        - E.g.: determining customer segments in marketing data (clustering), medical imaging, anomaly detection.
    - Reinforcement learning:
        - The most complex of these.
        - There is no data set provided to train it.
        - The agent learns by interacting with the environment in which it is placed.
        - It receives positive or negative rewards based on the actions it takes, and improves over time by refining its responses to maximize positive rewards.
        - E.g.: self-improving industrial robots, automated stock trading, advanced recommendation engines, bid optimization for maximizing ad spend.

## Deep learning
- Attempts to emulate human neural networks.
- Eliminates the need for pre-processed data.
- Able to ingest, process and analyse vast quantities of unstructured data to learn without any human intervention.
- Can improve over time.
- E.g.: computer vision, facial recognition, natural language processing.

---
